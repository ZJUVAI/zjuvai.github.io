---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Zhaosong Huang presenting VAST TVCG Paper “A Natural-language-based Visual Query Approach of Uncertain Human Trajectories” at IEEE VAST 2019"
event: IEEE VIS 2019 Searching & Querying
event_url: http://ieeevis.org/year/2019/welcome
location: Vancouver, Canada
summary: "VAST TVCG Paper: A Natural-language-based Visual Query Approach of Uncertain Human Trajectories."
abstract: "Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POIs and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: 2019-10-25T09:30:20+08:00
date_end: 2019-10-25T09:45:20+08:00
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: 2019-10-01T20:05:20+08:00

authors:
  [
    Zhaosong Huang,
    Ye Zhao,
    Wei Chen,
    Shengjie Gao,
    Kejie Yu,
    Weixia Xu,
    Mingjie Tang,
    Minfeng Zhu,
    Mingliang Xu,
  ]
tags: ["VIS2019"]

# Is this a featured talk? (true/false)
featured: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

# Optional filename of your slides within your talk's folder or a URL.
url_slides:
  - http://www.cad.zju.edu.cn/home/vagblog/slides/201911/Evaluating%20Perceptual%20Bias%20During%20Geometric%20Scaling%20of%20Scatterplots-final.pdf
url_code:
url_pdf:
  - http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/IEEEVAST2019_NLP_urban.pdf
url_video:
  - https://vimeo.com/372421808
url_demo:
  -

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---
